---
title: "p8105_hw2_jc5313"
output: github_document
date: "2022-10-05"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load_libraries}
library(tidyverse)
library(readxl)
```

## Problem 1

I am importing and cleaning the data from `NYC_Transit_Subway_Entrance_And_Exit_Data.csv`. The process begins with data import, updates variable names, and selects the columns that will be used in later parts fo this problem. We update `entry` from `yes` / `no` to a logical variable. As part of data import, we specify that `Route` columns 8-11 should be character for consistency with 1-7.

```{r}
trans_ent = 
  read_csv(
    "data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
    col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>% 
  janitor::clean_names() %>% 
  select(
    line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entry, exit_only, vending, entrance_type, 
    ada) %>% 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

As it stands, these data are not "tidy": route number should be a variable, as should route. That is, to obtain a tidy dataset we would need to convert `route` variables from wide to long format. This will be useful when focusing on specific routes, but may not be necessary when considering questions that focus on station-level variables. 

The following code chunk selects station name and line, and then uses `distinct()` to obtain all unique combinations. As a result, the number of rows in this dataset is the number of unique stations.

```{r}
trans_ent %>% 
  select(station_name, line) %>% 
  distinct
```

The next code chunk is similar, but filters according to ADA compliance as an initial step. This produces a dataframe in which the number of rows is the number of ADA compliant stations. 

```{r}
trans_ent %>% 
  filter(ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

To compute the proportion of station entrances / exits without vending allow entrance, we first exclude station entrances that do not allow vending. Then, we focus on the `entry` variable -- this logical, so taking the mean will produce the desired proportion (recall that R will coerce logical to numeric in cases like this).

```{r}
trans_ent %>% 
  filter(vending == "NO") %>% 
  pull(entry) %>% 
  mean
```

Lastly, we write a code chunk to identify stations that serve the A train, and to assess how many of these are ADA compliant. As a first step, we tidy the data as alluded to previously; that is, we convert `route` from wide to long format. After this step, we can use tools from previous parts of the question (filtering to focus on the A train, and on ADA compliance; selecting and using `distinct` to obtain dataframes with the required stations in rows).

```{r}
trans_ent %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A") %>% 
  select(station_name, line) %>% 
  distinct

trans_ent %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A", ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

## Problem 2

First, I am reading and cleaning the Mr. Trash Wheel sheet.
```{r}
mr_trash_wheel_data = read_excel("data/Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", range = "A2:N549") %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  mutate(year = as.numeric(year), sports_balls = as.integer(sports_balls))
```

Next, I am reading and cleaning the Professor Trash Wheel sheet.
```{r}
professor_trash_wheel_data = read_excel("data/Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", range = "A2:M96") %>%
  janitor::clean_names() %>%
  drop_na(dumpster) 
```

Next, I am producing a single tidy dataset.
```{r}
trash_wheel_data = full_join(mr_trash_wheel_data, professor_trash_wheel_data)
```

My new single tidy dataset has `r nrow(trash_wheel_data)` observations with the variables `r colnames(trash_wheel_data)`. A key variable is the `weight_tons` variable, and the total weight of trash collected by Professor Trash Wheel was `r sum(pull(professor_trash_wheel_data, weight_tons))`. Another key variable is the `sports_balls` variable, and the total number of sports balls collected by Mr. Trash Wheel in 2020 was `r filter(mr_trash_wheel_data, year == 2020) %>% {sum(.$sports_balls)}`.


## Problem 3

First, I clean the data in pols-month.csv.
```{r}
pols_data = read_csv("data/fivethirtyeight_datasets/pols-month.csv") %>%
  janitor::clean_names() %>%
  separate(mon, into = c("year", "month", "day"), sep = "-") %>%
  select(-day) %>%
  mutate(month = as.numeric(month),
         month = month.abb[month],
         month = str_to_lower(month),
         year = as.numeric(year),
         prez_dem = recode(prez_dem, `1` = "dem", `0` = "gop"),
         prez_gop = recode(prez_gop, `1` = "gop", `0` = "dem", `2` = "weird"),
         president = prez_dem) %>%
  select(-prez_gop, -prez_dem)
```

Second, I clean the data in snp.csv in a very similar way to what I did for pols-month.csv.
```{r}
snp_data = read_csv("data/fivethirtyeight_datasets/snp.csv") %>%
  janitor::clean_names() %>%
  separate(col = date, into = c("month", "day", "year"), sep = "/") %>%
  select(-day) %>%
  mutate(month = as.numeric(month),
         month = month.abb[month],
         month = str_to_lower(month),
         year = as.numeric(year), year = 2000+year) %>%
  arrange(year, month)
```

Third, I tidy the unemployment data so that it can be merged with the previous two datasets.
```{r}
unemployment_data = read_csv("data/fivethirtyeight_datasets/unemployment.csv") %>%
  janitor::clean_names() %>%
  pivot_longer(jan:dec, names_to = "month", values_to = "percent_unemployed") %>%
  mutate(month = as.numeric(month),
         month = month.abb[month],
         month = str_to_lower(month))
```

Now I join the datasets by merging snp_data into pols_data, and merging unemployment_data into the result.
```{r}
merged_snp_pols = left_join(pols_data, snp_data, by = c("year" = "year", "month" = "month"))
merged_snp_pols_unemployment = left_join(merged_snp_pols, unemployment_data,  by = c("year" = "year", "month" = "month"))
```

The pols dataset has `r nrow(pols_data)` rows and `r ncol(pols_data)` columns. The snp dataset has `r nrow(snp_data)` rows and `r ncol(snp_data)` columns. The unemployment dataset has `r nrow(unemployment_data)` rows and `r ncol(unemployment_data)` columns. The final dataset has `r nrow(merged_snp_pols_unemployment)` rows and `r ncol(merged_snp_pols_unemployment)` columns and has variables `r colnames(merged_snp_pols_unemployment)`. The year range is `r min(pull(merged_snp_pols_unemployment, year))` to `r max(pull(merged_snp_pols_unemployment, year))`.
